{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Little, Big Data using Colaboratory\n",
    "## For use with \"LittleBigData.py\"\n",
    "### Emily Stark\n",
    "### April, 30th, 2019\n",
    "\n",
    "This script is intended for use to analyze datasets with restricted sample size and high dimensional data. In order to complete this analysis, you must have LittleBigData.py in the same folder as this script. Your data do not need to be in the same directory, but the directory must be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive') # mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/...')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from LittleBigData import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Functions:\n",
    "\n",
    "*Preproc(x, w, Xstart, Xend, Wstart, Wend, trainfiledir, valfiledir, classtargets, header, testfiledir = None)*\n",
    " - **x** (integer), how many rows each input contains\n",
    " \n",
    " - **w** (integer), how many columns each input contains\n",
    " \n",
    " - **Xstart**, Xend, Wstart, Wend (integer), which row/column to start/end analysis, used for cropping\n",
    " \n",
    " - **trainfiledir**, **valfiledir**, **testfiledir** (string), file path to location of .csv files of data for training, validation, and testing (if provided)\n",
    " \n",
    " - **classtargets** (list), the marker in the file name that denotes ground truth label\n",
    " \n",
    " - **header** (interger), number of rows to skip in the .csv file of data\n",
    " \n",
    "***\n",
    "\n",
    "*Modeltrain(Xtrain, Ytrain, Xval, Yval, mname, net = '5FCN', ep = 80, bsize = 50)*\n",
    " - **Xtrain**, **Xval** (array), 4D tensor containing data with the first dimension representing inputs, second representing rows for each input, third represnting columns for each input, and fourth representing channels for each input (usually only 1).\n",
    " \n",
    " - **Ytrain**, **Yval** (array), one-hot vector containing ground truth labels for each input.\n",
    " \n",
    " - **mname** (string), name of the model for tensorboard and to save progress.\n",
    " \n",
    " - **net** (string or specified architecture), can choose '3FCN', '5FCN', or 'AlexNet' to select prewritten architectures or write your own and specify the variable name here. Default is 5FCN.\n",
    " \n",
    " - **ep** (integer), number of epochs. Defaul 80.\n",
    " \n",
    " - **bsize** (integer), batch size. Default 50.\n",
    " \n",
    " - - **OS** (string), either 'Colab' or 'Linux' used to show Tensorboard. If running on Windows, do not specify anything, defaults to None\n",
    " \n",
    "***\n",
    "\n",
    "*DeepDiscovery(Xval, Yval, classnames, n, modeldir = None, mname = None, model = None, net = '5FCN')*\n",
    " - **classnames** (list), character strings representing class names in the order of representation in the one-hot vector.\n",
    " \n",
    " - **n** (integer), number of inputs per sample.\n",
    " \n",
    " - **modeldir** (string) and **mname** (string), file path to the saved model and the model name to load in weights. Must either include this or model.\n",
    " \n",
    " - **model** (trained model), variable for the model already loaded into the jupyter notebook.\n",
    " \n",
    "***\n",
    "\n",
    "*GestaltDL(Xval, Yval, valnames, classnames, n, perc,  Xtest = None, Ytest = None, testnames = None, modeldir = None, mname = None, model = None, net = '5FCN')*\n",
    " - **valnames**/**testnames** (list), names of the samples in the validation/testing set (generally use file names).\n",
    " \n",
    " - **perc** (integer), number between 0 and 100 of the percentile of interest for identifying strong signals (i.e. if looking for the top 10% of signals, choose 90).\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completing Little, Big Data Analysis\n",
    "Use the following blocks of code to complete the preprocessing, model training, and postprocessing. Once the model is trained, DeepDiscovery will show where in the sample the model is confident in the correct classification across all classes. You may decide to crop to that region or continue on to GestaltDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to save my valnames and testnames\n",
    "import os\n",
    "import glob\n",
    "\n",
    "os.chdir('...')\n",
    "valnames = glob.glob('*csv')\n",
    "os.chdir('...')\n",
    "testnames = glob.glob('*csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain, Xval, Yval, Xtest, Ytest = Preproc(x = 1000, w = 100, Xstart = 0, Xend = 1000, \n",
    "                                                   Wstart = 0, Wend = 5000, \n",
    "        trainfiledir = '.../Train', \n",
    "        valfiledir = '.../Val', \n",
    "        testfiledir = '.../Test', \n",
    "        classtargets = ['A','B'], header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended that you save your tensors as .npy files so you can load them in without having to preprocess your data again. To do so, change your directory and use the np.save commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('.../NumpyData')\n",
    "np.save('Xtrain.npy', Xtrain)\n",
    "np.save('Ytrain.npy', Ytrain)\n",
    "np.save('Xval.npy', Xval)\n",
    "np.save('Yval.npy', Yval)\n",
    "np.save('Xtest.npy', Xtest)\n",
    "np.save('Ytest.npy', Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train a different network, you can copy the code below:\n",
    "\n",
    "os.chdir('/content/drive/My Drive/Olfaction/Dissemination/Presentations/2019.05.26 ISOEN Tutorial/FvsChi_Data/NumpyData')\n",
    "\n",
    "Xtrain = np.load('Xtrain.npy') ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying New Achitecture\n",
    "If you do not want to use one of the preloaded architectures (3-hidden layer fully connected, 5-hidden layer fully connected, or AlexNet) you are welcome to specify your own using TFLearn/Tensorflow. An example of a 1-hidden layer fully connected network is shown below. It is recommendended not to alter the input or output layer, as these will ensure your network is properly set up to take in the appropriately sized data and output the correct number of probabilistic values. When you have written your architecture, instead of including one of the three specified strings for \"net\" in *Modeltrain*, just include the variable name for your network (in the example below, \"mynet\").\n",
    "\n",
    "If you want to write your own network, you need to import necessary functions/libraries explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_utils import to_categorical\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = input_data(shape = [None, Xtrain.shape[1], Xtrain.shape[2], Xtrain.shape[3]])\n",
    "mynet = fully_connected(mynet, 2000, activation='tanh')\n",
    "mynet = fully_connected(mynet, Ytrain.shape[1], activation='softmax')\n",
    "mynet = regression(mynet, optimizer='momentum',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "To save your model in a specific location, before training your model you will need to change directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('.../Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = Modeltrain(Xtrain = Xtrain, Ytrain = Ytrain, Xval = Xval, Yval = Yval, \n",
    "           mname = 'testestest', arch = mynet, ep = 2, bsize = 100, OS = 'Colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save your trained model, it is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.save('mymodel_testestest123')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below will work with either saved models or with models that you have trained during the runtime of this notebook. If you load in the saved model, you will use the \"modeldir\" and \"mname\" arguments. If you use a model that is already loaded into the notebook (for example, if you just trained it) you will use the \"model\" argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepDiscovery(Xval = Xval, Yval = Yval, classnames = ['A', 'B'], \n",
    "              n = 50, model = mymodel, net = mynet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestalt Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GestaltDL(Xval = Xval, Yval = Yval, valnames = valnames, classnames = ['A', 'B'],\n",
    "          n = 50, perc = 90,  Xtest = Xtest, Ytest = Ytest, testnames = testnames, \n",
    "          model = mymodel, net = mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
